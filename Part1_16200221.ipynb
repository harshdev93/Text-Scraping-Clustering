{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import requests\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "url = \"http://mlg.ucd.ie/modules/COMP41680/news/index.html\"  #main URL\n",
    "response = urllib.request.urlopen(url)\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response, 'html.parser')\n",
    "list_months = []\n",
    "for a in soup.findAll('a', href=True): #get all hyperlinks\n",
    "    list_months.append(\"http://mlg.ucd.ie/modules/COMP41680/news/\"+a['href']) #get all links and concatinate to the main lonk and append to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "del list_months[-3:] #del the last 3 links as they are useless\n",
    "#for i in list_months:\n",
    "#    print(i)\n",
    "\n",
    "list_final = []\n",
    "for i in list_months:\n",
    "    response = urllib.request.urlopen(i)\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    for a in soup.findAll('a', href=True):\n",
    "        #print(a)\n",
    "        if (a!=\"\" or a != \"index.html\" ): #dont select empty or index.html links\n",
    "            #print(a['href'])\n",
    "            list_final.append(\"http://mlg.ucd.ie/modules/COMP41680/news/\"+a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "count = 0\n",
    "list_final_updated = []\n",
    "for i in list_final:\n",
    "    #if a link contains index.html or \"http://mlg.ucd.ie/modules/COMP41680/news/\" then go to next link\n",
    "    search = re.search(r'\\bindex.html\\b',i)\n",
    "    if (search):\n",
    "        continue\n",
    "    if (i == \"http://mlg.ucd.ie/modules/COMP41680/news/\"):\n",
    "        continue\n",
    "    else:\n",
    "        list_final_updated.append(i) #final updated list of all links\n",
    "     \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in list_final_updated:\n",
    "    f_name = (i.split(\"/\")[-1]).split(\".\")[0]+\".txt\" #create a unique file name for each document\n",
    "    #print(f_name)\n",
    "    response = urllib.request.urlopen(i)\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    p = soup.find_all('p')\n",
    "    for j in p:\n",
    "        with open(f_name,'a',encoding=\"utf-8\") as csv_file: #open each link and get its text without tags and save ina  txt file\n",
    "            csv_file.write(j.get_text())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
